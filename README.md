# Netflix-Project
# 🚀 Netflix Azure Data Engineering Project

## 📌 Overview
This repository contains resources for building and managing **Azure Data Engineering solutions**, covering **data ingestion, transformation, orchestration, and real-time analytics**. It provides a structured **end-to-end data pipeline** using **Azure Data Factory, Databricks, PySpark, Apache Spark**, and **Delta Live Tables**.

## 🔑 Key Features
- **End-to-End Data Pipelines** – Scalable and efficient workflows for structured data processing.
- **ETL & Data Processing** – Uses **Azure Data Factory** for ingestion and **Databricks** for transformation.
- **Big Data & Real-Time Analytics** – Implements **PySpark, Apache Spark, and Delta Live Tables**.
- **Incremental Data Loading** – Leverages **Databricks Autoloader** for efficiency.
- **Workflow Orchestration** – Automates and optimizes pipelines with **Databricks Workflows**.
- **Cloud-Based Solution** – Built on **Azure Data Factory, Databricks, and Data Lake Gen2**.

## 🎯 Use Cases
✔️ Develop and manage **ETL, Big Data, and Real-Time Processing** solutions.  
✔️ Implement **Azure Data Factory, Databricks, and PySpark** for efficient data engineering.  
✔️ Optimize **scalable and automated data workflows**.

## 🛠️ Technologies Used
- **Azure Data Factory (ADF)** – Data orchestration and pipeline management.
- **Azure Data Lake Gen2** – Scalable and secure data storage.
- **Azure Databricks** – Advanced data transformation with **Apache Spark**.
- **PySpark** – Big data processing and analytics.
- **Apache Spark Streaming** – Real-time data processing.
- **Databricks Delta Live Tables** – Efficient data pipeline automation.

## 🏗️ Data Architecture
This project follows a structured **data lakehouse architecture**:
1. **Raw Data Layer (Bronze Layer)** – Ingests data using **Azure Data Factory**.
2. **Cleansed Data Layer (Silver Layer)** – Processes and transforms data in **Databricks with PySpark**.
3. **Curated Data Layer (Gold Layer)** – Optimized for analytics in **Databricks Delta Live Tables**.
4. **Real-Time Processing** – Implemented using **Spark Streaming and Databricks Autoloader**.
5. **End-to-End Data Pipeline** – Orchestrated with **Databricks Workflows**.
<img width="499" alt="image" src="https://github.com/user-attachments/assets/9c01d883-189a-4a12-89d9-4dde12cf7402" />


## 📁 Data Sources
- **Dataset from API and Azure Storage** – Processed through the pipeline.
- **Original Dataset** – Hosted on Kaggle.

Happy Learning! 🚀



